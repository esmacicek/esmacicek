{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "1zlQ_b3kcEYqI3fyL63780z5Gs5yLW_lO",
      "authorship_tag": "ABX9TyN6YUdwyO0XGlxgI6BJhvze",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/esmacicek/esmacicek/blob/main/vgg_egitim5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OyEFhGrGn_D",
        "outputId": "6cd65316-cec4-466f-a97f-089d0cf0d187"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6796 images belonging to 4 classes.\n",
            "Found 2266 images belonging to 4 classes.\n",
            "Epoch 1/50\n",
            "106/106 [==============================] - 376s 4s/step - loss: 1.3921 - accuracy: 0.2995 - val_loss: 1.3469 - val_accuracy: 0.3585\n",
            "Epoch 2/50\n",
            "106/106 [==============================] - 116s 1s/step - loss: 1.3360 - accuracy: 0.3460 - val_loss: 1.3684 - val_accuracy: 0.3205\n",
            "Epoch 3/50\n",
            "106/106 [==============================] - 114s 1s/step - loss: 1.3475 - accuracy: 0.3394 - val_loss: 1.2887 - val_accuracy: 0.3750\n",
            "Epoch 4/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 1.2838 - accuracy: 0.3770 - val_loss: 1.2755 - val_accuracy: 0.3826\n",
            "Epoch 5/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 1.2292 - accuracy: 0.4078 - val_loss: 1.1631 - val_accuracy: 0.4339\n",
            "Epoch 6/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 1.1626 - accuracy: 0.4367 - val_loss: 1.0877 - val_accuracy: 0.4616\n",
            "Epoch 7/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 1.1186 - accuracy: 0.4542 - val_loss: 1.0890 - val_accuracy: 0.4929\n",
            "Epoch 8/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 1.0874 - accuracy: 0.4860 - val_loss: 1.0228 - val_accuracy: 0.5094\n",
            "Epoch 9/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 1.0130 - accuracy: 0.5266 - val_loss: 0.9272 - val_accuracy: 0.5562\n",
            "Epoch 10/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.9598 - accuracy: 0.5499 - val_loss: 0.8272 - val_accuracy: 0.6205\n",
            "Epoch 11/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.8743 - accuracy: 0.5967 - val_loss: 0.9088 - val_accuracy: 0.5540\n",
            "Epoch 12/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.8442 - accuracy: 0.6052 - val_loss: 0.7524 - val_accuracy: 0.6366\n",
            "Epoch 13/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.7348 - accuracy: 0.6463 - val_loss: 0.6414 - val_accuracy: 0.6920\n",
            "Epoch 14/50\n",
            "106/106 [==============================] - 116s 1s/step - loss: 0.6648 - accuracy: 0.6814 - val_loss: 0.5668 - val_accuracy: 0.7339\n",
            "Epoch 15/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.6488 - accuracy: 0.6852 - val_loss: 0.5560 - val_accuracy: 0.7424\n",
            "Epoch 16/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.5985 - accuracy: 0.7096 - val_loss: 0.5528 - val_accuracy: 0.7312\n",
            "Epoch 17/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.5903 - accuracy: 0.7151 - val_loss: 0.5122 - val_accuracy: 0.7616\n",
            "Epoch 18/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.5665 - accuracy: 0.7221 - val_loss: 0.5034 - val_accuracy: 0.7621\n",
            "Epoch 19/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.5393 - accuracy: 0.7288 - val_loss: 0.4853 - val_accuracy: 0.7629\n",
            "Epoch 20/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.5436 - accuracy: 0.7366 - val_loss: 0.4637 - val_accuracy: 0.7674\n",
            "Epoch 21/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.5462 - accuracy: 0.7311 - val_loss: 0.5741 - val_accuracy: 0.7344\n",
            "Epoch 22/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.5097 - accuracy: 0.7433 - val_loss: 0.4604 - val_accuracy: 0.7790\n",
            "Epoch 23/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.4883 - accuracy: 0.7644 - val_loss: 0.4512 - val_accuracy: 0.7799\n",
            "Epoch 24/50\n",
            "106/106 [==============================] - 116s 1s/step - loss: 0.4819 - accuracy: 0.7605 - val_loss: 0.4696 - val_accuracy: 0.7844\n",
            "Epoch 25/50\n",
            "106/106 [==============================] - 116s 1s/step - loss: 0.4731 - accuracy: 0.7686 - val_loss: 0.5152 - val_accuracy: 0.7652\n",
            "Epoch 26/50\n",
            "106/106 [==============================] - 116s 1s/step - loss: 0.4818 - accuracy: 0.7650 - val_loss: 0.4794 - val_accuracy: 0.7777\n",
            "Epoch 27/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.4732 - accuracy: 0.7622 - val_loss: 0.4357 - val_accuracy: 0.7871\n",
            "Epoch 28/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.4515 - accuracy: 0.7758 - val_loss: 0.4083 - val_accuracy: 0.8089\n",
            "Epoch 29/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.4500 - accuracy: 0.7848 - val_loss: 0.4776 - val_accuracy: 0.7567\n",
            "Epoch 30/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.4458 - accuracy: 0.7819 - val_loss: 0.4050 - val_accuracy: 0.8058\n",
            "Epoch 31/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.4651 - accuracy: 0.7779 - val_loss: 0.4943 - val_accuracy: 0.7786\n",
            "Epoch 32/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.4280 - accuracy: 0.8007 - val_loss: 0.4209 - val_accuracy: 0.7991\n",
            "Epoch 33/50\n",
            "106/106 [==============================] - 117s 1s/step - loss: 0.4279 - accuracy: 0.7959 - val_loss: 0.3942 - val_accuracy: 0.8112\n",
            "Epoch 34/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.3984 - accuracy: 0.8118 - val_loss: 0.3782 - val_accuracy: 0.8147\n",
            "Epoch 35/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.4024 - accuracy: 0.8099 - val_loss: 0.3938 - val_accuracy: 0.8121\n",
            "Epoch 36/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.3760 - accuracy: 0.8253 - val_loss: 0.3601 - val_accuracy: 0.8353\n",
            "Epoch 37/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.3748 - accuracy: 0.8268 - val_loss: 0.3526 - val_accuracy: 0.8379\n",
            "Epoch 38/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.3699 - accuracy: 0.8357 - val_loss: 0.3955 - val_accuracy: 0.8156\n",
            "Epoch 39/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.3528 - accuracy: 0.8408 - val_loss: 0.3822 - val_accuracy: 0.8205\n",
            "Epoch 40/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.3510 - accuracy: 0.8433 - val_loss: 0.3527 - val_accuracy: 0.8326\n",
            "Epoch 41/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.3384 - accuracy: 0.8476 - val_loss: 0.3278 - val_accuracy: 0.8487\n",
            "Epoch 42/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.3343 - accuracy: 0.8498 - val_loss: 0.4154 - val_accuracy: 0.8214\n",
            "Epoch 43/50\n",
            "106/106 [==============================] - 116s 1s/step - loss: 0.3158 - accuracy: 0.8602 - val_loss: 0.3054 - val_accuracy: 0.8576\n",
            "Epoch 44/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.3074 - accuracy: 0.8650 - val_loss: 0.2955 - val_accuracy: 0.8625\n",
            "Epoch 45/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.2956 - accuracy: 0.8714 - val_loss: 0.3179 - val_accuracy: 0.8545\n",
            "Epoch 46/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.2792 - accuracy: 0.8769 - val_loss: 0.2696 - val_accuracy: 0.8866\n",
            "Epoch 47/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.2692 - accuracy: 0.8852 - val_loss: 0.2812 - val_accuracy: 0.8772\n",
            "Epoch 48/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.2891 - accuracy: 0.8773 - val_loss: 0.2781 - val_accuracy: 0.8777\n",
            "Epoch 49/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.2596 - accuracy: 0.8899 - val_loss: 0.2635 - val_accuracy: 0.8853\n",
            "Epoch 50/50\n",
            "106/106 [==============================] - 115s 1s/step - loss: 0.2509 - accuracy: 0.8962 - val_loss: 0.2565 - val_accuracy: 0.8933\n",
            "Found 2068 images belonging to 4 classes.\n",
            "65/65 [==============================] - 370s 6s/step - loss: 0.2838 - accuracy: 0.8709\n",
            "Test Accuracy: 0.8708897233009338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# Gerekli kütüphaneleri yükleyin\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Model\n",
        "# Veri yolu\n",
        "train_path = '/content/drive/MyDrive/alz.dmn.project/Split/Train'\n",
        "valid_path = '/content/drive/MyDrive/alz.dmn.project/Split/Validation'\n",
        "test_path = '/content/drive/MyDrive/alz.dmn.project/Split/Test'\n",
        "\n",
        "# Veri artırımı konfigürasyonu\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    rescale=1./255\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    rescale=1./255\n",
        ")\n",
        "\n",
        "# Veri setini yükleyin ve artırın\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    valid_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# VGG16 modelini kullanın\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Yeni bir model oluşturun ve VGG16 modelini ekleyin\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "# Modeli derleyin\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=optimizers.Adam(learning_rate=0.0001),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Modeli eğitin\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    epochs=50,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
        ")\n",
        "\n",
        "# Modeli değerlendirin\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "accuracy = model.evaluate(test_generator)\n",
        "print('Test Accuracy:', accuracy[1])\n",
        "\n",
        "model.save('/content/drive/MyDrive/alz.dmn.project/Model/vgg.model.son.h5')"
      ]
    }
  ]
}